{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40a544ce",
   "metadata": {},
   "source": [
    "## CM3015 Midterm Coursework\n",
    "**Aim: Comparison and finding of best ML model for dataset**\n",
    "<br>(for example, k-means vs other clustering algorithms)\n",
    "\n",
    "**Chosen dataset: Hand-written digits dataset on scikit-learn**\n",
    "<br>(no credit for manipulation of data prior to analysis)\n",
    "\n",
    "### Algorithms\n",
    "You should apply at least **two machine learning algorithms** from the first part of this module to your chosen problem. Specifically, at least two from: kNN, decision trees, linear regression, gradient descent, polynomial regression, Bayesian classification, k-means and PCA.\n",
    "\n",
    "You should implement at least one of the ML algorithms from scratch. This / these implementation(s) must be in standard Python code and should not refer to any machine learning libraries. The use of numpy and matplotlib is permissible (and expected).\n",
    "\n",
    "### Methodology, Analysis and Evaluation\n",
    "The first half of this module (Topics 1-6) introduced several important ML techniques such as Training/test set splitting, classifier evaluation metrics (precision, accuracy, ...), data scaling, over/under fitting, regularisation and cross-validation. You should utilise these techniques wherever appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b736898",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set matplotlib backend to inline\n",
    "%matplotlib inline\n",
    "\n",
    "## import modules\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f328cf42",
   "metadata": {},
   "source": [
    "### Importing dataset\n",
    "This coursework focuses on the **hand-written digits** dataset from scikit-learn. This is a 1797 sample data categorising 10 digits using 16 features.\n",
    "\n",
    "The first step is to load the dataset, and understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcab8467",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading digits dataset\n",
    "digits = datasets.load_digits()\n",
    "# print(\"feature_names:\", digits.feature_names)\n",
    "# print(\"target:\", digits.target)\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70429382",
   "metadata": {},
   "source": [
    "### Implementing kNN\n",
    "The first model chosen for implementation is the k-Nearest Neighbour classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77dafec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper code for kNN\n",
    "## 1. distance calculator\n",
    "def cal_dist(a, b, dist_type):\n",
    "    '''\n",
    "    calculates distance between 2 data points\n",
    "    -----\n",
    "    Inputs:\n",
    "    \t- a: data input 1\n",
    "        - b: data input 2\n",
    "        - dist_type: type of distance calculation\n",
    "          > manhattan or euclidean\n",
    "        \n",
    "    Output:\n",
    "    \t- dist: distance calculated between the data points\n",
    "    -----\n",
    "    '''\n",
    "    \n",
    "    if dist_type == \"euclidean\":\n",
    "        dist = np.linalg.norm(a-b, axis = 0)\n",
    "        return dist\n",
    "    elif dist_type == \"manhattan\":\n",
    "        dist = 0\n",
    "        for i in range(len(a)):\n",
    "            dist += math.fabs(a[i] - b[i])\n",
    "        return dist\n",
    "    \n",
    "## 2. train-test split\n",
    "def train_test_split(X, y, test_size):\n",
    "    '''\n",
    "    splitting data input and labels based on test_size\n",
    "    -----\n",
    "    Inputs:\n",
    "    \t- X: input data\n",
    "        - y: input labels\n",
    "        - test_size: portion if dataset to be test set (between 0 and 1)\n",
    "    \n",
    "    Outputs:\n",
    "    \t- X_train: array of training data\n",
    "        - X_test: array of testing data\n",
    "        - y_train: array of training labels\n",
    "        - y_test: array of testing labels for prediction\n",
    "    -----\n",
    "    '''\n",
    "    \n",
    "    ## randomising input using fixed seed\n",
    "    np.random.seed(28)\n",
    "    ## changing X to evenly spaced elements based on input\n",
    "    lis = np.arange(X.shape[0])\n",
    "    ## randomising sequence\n",
    "    lis = np.random.permutation(lis)\n",
    "    X = X[lis]\n",
    "    y = y[lis]\n",
    "    \n",
    "    ## slicing start based on test_size for test data\n",
    "    slice_idx = int(len(X) * test_size)\n",
    "    X_test = X[:slice_idx]\n",
    "    y_test = y[:slice_idx]\n",
    "    \n",
    "    # slicing end based on test_size for train data\n",
    "    X_train = X[slice_idx:]\n",
    "    y_train = y[slice_idx:]\n",
    "    \n",
    "    return(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71c7d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNNAlgo(X_train, y_train, X_test, k, dist_type):\n",
    "    '''\n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81101663",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
